# ğŸš€ Project ORBIT â€” PE Dashboard for Forbes AI 50  
### *DAMG7245 â€” Assignment 2 | Northeastern University*

> ğŸŸ¢ **Live Dashboard:** *[https://pe-dashboard-ui-ca7qaibdpa-uc.a.run.app/]*
> ğŸ¥ **Demo Video:** *[https://northeastern-my.sharepoint.com/:v:/g/personal/gandhi_di_northeastern_edu/ERbw5r7rYJ9DmqTFlHo7Kp8BJcuYJRMsHnNscO-dYMLyaA?e=xmmzAs&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZy1MaW5rIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXcifX0%3D]*  

---

## ğŸ“˜ Overview  

**Project ORBIT â€” PE Dashboard** is an end-to-end data intelligence system that ingests, structures, and evaluates information for the **Forbes AI 50 companies**.  
It combines **ETL automation, AI data extraction, and evaluation pipelines** to build a dynamic investor-style dashboard that visualizes structured company profiles and evaluation metrics.  

This project demonstrates complete integration between:  
- ğŸ§© **FastAPI backend** for serving company data  
- ğŸ§  **LangChain-based RAG and Structured extraction** for text synthesis  
- âš™ï¸ **Airflow DAGs** for daily refresh automation  
- ğŸŒ **Streamlit UI** for interactive visualization  
- â˜ï¸ **Terraform + GitHub Actions + Google Cloud Run deployment**  

---

## Architecture Diagram  

![alt text](architecture.png)

---

## ğŸ§© Repository Structure  

```
pe-dashboard-ai50/
â”œâ”€â”€ app.py                        # FastAPI application entry point
â”œâ”€â”€ streamlit_app.py              # Streamlit dashboard interface
â”œâ”€â”€ dashboard_prompt.txt          # Dashboard UI prompt templates
â”œâ”€â”€ docker-compose.yml            # Combined Streamlit + FastAPI container setup
â”œâ”€â”€ Dockerfile.fastapi            # API service Dockerfile
â”œâ”€â”€ Dockerfile.streamlit          # UI service Dockerfile
â”œâ”€â”€ dags/                         # Airflow DAGs for scheduled refresh
â”œâ”€â”€ data/                         # Raw + processed + payload data
â”œâ”€â”€ src/                          # Core source code
â”œâ”€â”€ terraform/                    # Infrastructure as Code (Cloud Run, Storage, SQL)
â”œâ”€â”€ .github/workflows/            # GitHub Actions CI/CD for deployment
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ EVAL.md
â””â”€â”€ reflection_lab9.md
```

---

## âš™ï¸ Run Locally (Dev Mode)

```bash
# 1ï¸âƒ£ Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Run FastAPI backend
uvicorn src.api:app --reload
# API available at http://localhost:8000

# 4ï¸âƒ£ In another terminal, launch Streamlit UI
streamlit run src/streamlit_app.py
# Dashboard available at http://localhost:8501
```

---

## ğŸ³ Run with Docker

```bash
# Build and run both FastAPI + Streamlit containers
docker compose up --build
```

This starts:

- **Streamlit** â†’ [https://pe-dashboard-ui-ca7qaibdpa-uc.a.run.app/] 

---

## â˜ï¸ Cloud Deployment (Terraform + GitHub Actions + Cloud Run)

You can deploy the app using **Terraform + Google Cloud Run + GitHub Actions**:

1. Configure credentials in your Terraform backend (`terraform/variables.tf`).  
2. Deploy infrastructure via:  
   ```bash
   cd terraform
   terraform init
   terraform apply
   ```  
3. **Terraform** provisions all required cloud resources â€” including Cloud Run services, Cloud SQL database, and GCS buckets.  
4. **GitHub Actions** automates CI/CD â€” once new code is pushed to the main branch, it triggers deployment, builds Docker images, and updates the running containers on Cloud Run automatically.  
5. Cloud Run hosts both **FastAPI** and **Streamlit** containers for scalable access.  
6. The daily **Airflow DAG** refreshes `data/payloads/` for the dashboard, keeping the live app synced with new data.  

> ğŸ§© *All DAGs are Composer-ready for automated, production-scale scheduling.*

---

## ğŸ§ª Evaluation  

Each company was scored on a **10-point rubric** (Factual 3, Schema 2, Provenance 2, Hallucination 2, Readability 1).  

ğŸ“Š **Average Results:**
- RAG Pipeline â†’ 7.2 / 10  
- Structured Pipeline â†’ 10 / 10  

ğŸ“„ Full details in [`EVAL.md`](EVAL.md).  

---

## ğŸ’¡ Key Features  

- ğŸŒ Multi-source scraping (Forbes AI 50, Crunchbase, TechCrunch, LinkedIn)  
- âš™ï¸ Intelligent extraction via **Requests â†’ Selenium â†’ Playwright fallback**  
- ğŸ§  RAG vs Structured data comparison  
- ğŸ“ˆ Quantitative evaluation with automated scoring  
- ğŸŒ Streamlit dashboard for company exploration  
- â˜ï¸ CI/CD via Terraform + GitHub Actions for reproducible cloud deployment  

---

## ğŸ§± Tech Stack  

| Layer | Tools |
|:------|:------|
| **Backend** | Python 3.10 â€¢ FastAPI â€¢ LangChain â€¢ Pinecone â€¢ OpenAI Embeddings |
| **Frontend** | Streamlit â€¢ Plotly â€¢ Pandas |
| **Infra / DevOps** | Docker â€¢ Terraform â€¢ GitHub Actions â€¢ GCP (Cloud Run + Cloud Storage + Cloud SQL) |
| **Automation** | Apache Airflow / Composer â€¢ DAG-based refresh |
| **Data Quality** | JSON schema validation â€¢ rubric scoring â€¢ provenance tracking |

---

## ğŸ“º Demo Video  

ğŸ¥ *[https://northeastern-my.sharepoint.com/:v:/g/personal/gandhi_di_northeastern_edu/ERbw5r7rYJ9DmqTFlHo7Kp8BJcuYJRMsHnNscO-dYMLyaA?e=xmmzAs&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZy1MaW5rIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXcifX0%3D]*  
Explains data ingestion â†’ evaluation â†’ dashboard visualization flow.

---

## ğŸ§© CodeLabs  

ğŸ”— [View CodeLab â†’](index.html)
Step-by-step guide through pipeline design and evaluation.

---

## ğŸ Summary  

Project ORBIT â€“ PE Dashboard showcases a complete **AI data engineering pipeline**, integrating web scraping, knowledge extraction, structured evaluation, and live visualization.  

The project demonstrates how **structured pipelines** outperform generative ones in factual reliability while **RAG models** provide rich contextual insights â€” together creating a balanced, production-grade data intelligence system.
