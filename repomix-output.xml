This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
dags/
  ai50_daily_refresh_dag.py
  ai50_full_ingest_dag.py
data/
  forbes_ai50_seed.json
  sample_dashboard.md
  starter_payload.json
docker/
  docker-compose.yml
  Dockerfile
src/
  prompts/
    dashboard_system.md
  api.py
  evaluator.py
  models.py
  rag_pipeline.py
  streamlit_app.py
  structured_pipeline.py
.gitignore
Assignment.md
CONTRIBUTION_ATTESTATION.txt
EVAL.md
LICENSE
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="dags/ai50_daily_refresh_dag.py">
from datetime import datetime
from airflow import DAG
from airflow.operators.python import PythonOperator

def refresh_changed(**context):
    print("Refreshing changed companies...")

with DAG(
    dag_id="ai50_daily_refresh_dag",
    start_date=datetime(2025, 10, 31),
    schedule="0 3 * * *",
    catchup=False,
    tags=["ai50", "orbit", "daily"],
) as dag:

    t1 = PythonOperator(
        task_id="refresh_changed_companies",
        python_callable=refresh_changed,
    )
</file>

<file path="dags/ai50_full_ingest_dag.py">
from datetime import datetime
from airflow import DAG
from airflow.operators.python import PythonOperator
from pathlib import Path
import json

DATA_DIR = Path("/opt/airflow/data")

def load_company_list(**context):
    seed_path = DATA_DIR / "forbes_ai50_seed.json"
    companies = json.loads(seed_path.read_text())
    return companies

def scrape_all(**context):
    companies = context["ti"].xcom_pull(task_ids="load_company_list")
    out = []
    for c in companies:
        out.append({"company_name": c["company_name"], "status": "scraped"})
    (DATA_DIR / "raw").mkdir(parents=True, exist_ok=True)
    (DATA_DIR / "raw" / "ingest_log.json").write_text(json.dumps(out, indent=2))

with DAG(
    dag_id="ai50_full_ingest_dag",
    start_date=datetime(2025, 10, 31),
    schedule="@once",
    catchup=False,
    tags=["ai50", "orbit"],
) as dag:

    t1 = PythonOperator(
        task_id="load_company_list",
        python_callable=load_company_list,
    )

    t2 = PythonOperator(
        task_id="scrape_all_companies",
        python_callable=scrape_all,
    )

    t1 >> t2
</file>

<file path="data/forbes_ai50_seed.json">
[
  {
    "company_name": "PLACEHOLDER AI 1",
    "website": "https://example.com",
    "linkedin": "https://www.linkedin.com/company/example/",
    "hq_city": null,
    "hq_country": null,
    "category": null
  }
]
</file>

<file path="data/sample_dashboard.md">
## Company Overview
Example AI Inc. (“ExampleAI”) is a San Francisco, CA–based AI company founded in 2021, operating in the vertical_ai and ml_ops categories. Related companies include Scale AI and Cohere.

## Business Model and GTM
The company sells to enterprises with per-seat pricing and public tiers “Pro” and “Enterprise.” Integrations with Salesforce and Snowflake indicate an enterprise-led GTM motion.

## Funding & Investor Profile
On 2025-06-10 the company announced a $50M Series B led by Sequoia Capital. Total raised: $50M. Valuation not disclosed.

## Growth Momentum
As of 2025-10-31 the company reports ~120 headcount, ~35% growth and 18 open roles, with emphasis on Applied ML and Enterprise Sales.

## Visibility & Market Sentiment
42 news mentions in 30 days, avg sentiment 0.7, GitHub 1200 stars, Glassdoor 4.3.

## Risks and Challenges
- Valuation not disclosed.
- Competitive pressure from Scale AI, Cohere.

## Outlook
Well-positioned for GTM expansion if it can convert enterprise pipeline.

## Disclosure Gaps
- Valuation not disclosed.
- Customer counts not disclosed.
- Headcount growth inferred from careers page, LinkedIn not confirmed.
</file>

<file path="data/starter_payload.json">
{
  "company_record": {
    "company_id": "00000000-0000-0000-0000-000000000000",
    "legal_name": "Example AI Inc.",
    "brand_name": "ExampleAI",
    "website": "https://example.ai",
    "hq_city": "San Francisco",
    "hq_state": "CA",
    "hq_country": "US",
    "founded_year": 2021,
    "categories": [
      "vertical_ai",
      "ml_ops"
    ],
    "related_companies": [
      "Scale AI",
      "Cohere"
    ],
    "total_raised_usd": 50000000,
    "last_disclosed_valuation_usd": null,
    "last_round_name": "Series B",
    "last_round_date": "2025-06-10",
    "schema_version": "2.0.0",
    "as_of": "2025-10-31",
    "provenance": [
      {
        "source_url": "https://example.ai/about",
        "crawled_at": "2025-10-31T10:00:00Z",
        "snippet": "ExampleAI builds automation tooling..."
      }
    ]
  },
  "events": [
    {
      "event_id": "11111111-1111-1111-1111-111111111111",
      "company_id": "00000000-0000-0000-0000-000000000000",
      "occurred_on": "2025-06-10",
      "event_type": "funding",
      "title": "Series B funding",
      "description": "Raised $50M Series B led by Sequoia",
      "round_name": "Series B",
      "investors": [
        "Sequoia Capital"
      ],
      "amount_usd": 50000000,
      "valuation_usd": null,
      "actors": [
        "Sequoia Capital"
      ],
      "tags": [
        "funding",
        "growth"
      ],
      "schema_version": "2.0.0",
      "provenance": [
        {
          "source_url": "https://example.ai/blog/series-b",
          "crawled_at": "2025-10-31T10:00:00Z",
          "snippet": "We raised a $50M Series B led by Sequoia..."
        }
      ]
    }
  ],
  "snapshots": [
    {
      "company_id": "00000000-0000-0000-0000-000000000000",
      "as_of": "2025-10-31",
      "headcount_total": 120,
      "headcount_growth_pct": 35.0,
      "job_openings_count": 18,
      "engineering_openings": 10,
      "sales_openings": 4,
      "hiring_focus": [
        "Applied ML",
        "Enterprise sales"
      ],
      "pricing_tiers": [
        "Pro",
        "Enterprise"
      ],
      "active_products": [
        "Compliance Copilot"
      ],
      "geo_presence": [
        "SF",
        "NYC",
        "London"
      ],
      "confidence": 0.9,
      "schema_version": "2.0.0",
      "provenance": [
        {
          "source_url": "https://example.ai/careers",
          "crawled_at": "2025-10-31T10:00:00Z",
          "snippet": "We're hiring across engineering and GTM..."
        }
      ]
    }
  ],
  "products": [
    {
      "product_id": "22222222-2222-2222-2222-222222222222",
      "company_id": "00000000-0000-0000-0000-000000000000",
      "name": "Compliance Copilot",
      "description": "Automates regulatory review for enterprise finance workflows.",
      "pricing_model": "per-seat",
      "pricing_tiers_public": [
        "Pro",
        "Enterprise"
      ],
      "ga_date": "2024-11-01",
      "integration_partners": [
        "Salesforce",
        "Snowflake"
      ],
      "github_repo": null,
      "license_type": null,
      "reference_customers": [
        "MegaBank Inc."
      ],
      "schema_version": "2.0.0",
      "provenance": [
        {
          "source_url": "https://example.ai/product",
          "crawled_at": "2025-10-31T10:00:00Z",
          "snippet": "Compliance Copilot integrates with Salesforce..."
        }
      ]
    }
  ],
  "leadership": [
    {
      "person_id": "33333333-3333-3333-3333-333333333333",
      "company_id": "00000000-0000-0000-0000-000000000000",
      "name": "Jane Doe",
      "role": "CTO",
      "is_founder": false,
      "start_date": "2025-05-15",
      "end_date": null,
      "previous_affiliation": "ex-DeepMind",
      "education": "PhD ML, Stanford",
      "linkedin": "https://www.linkedin.com/in/janedoe",
      "schema_version": "2.0.0",
      "provenance": [
        {
          "source_url": "https://example.ai/blog/welcome-cto",
          "crawled_at": "2025-10-31T10:00:00Z",
          "snippet": "We're thrilled to welcome Jane Doe as CTO..."
        }
      ]
    }
  ],
  "visibility": [
    {
      "company_id": "00000000-0000-0000-0000-000000000000",
      "as_of": "2025-10-31",
      "news_mentions_30d": 42,
      "avg_sentiment": 0.7,
      "github_stars": 1200,
      "glassdoor_rating": 4.3,
      "schema_version": "2.0.0",
      "provenance": [
        {
          "source_url": "https://technews.example.com/exampleai-raises",
          "crawled_at": "2025-10-31T10:00:00Z",
          "snippet": "ExampleAI announced new funding and hiring push..."
        }
      ]
    }
  ],
  "notes": "",
  "provenance_policy": "Use only the sources you scraped. If a field is missing, write 'Not disclosed.' Do not infer valuation."
}
</file>

<file path="docker/docker-compose.yml">
version: "3.9"

services:
  app:
    build: ..
    container_name: pe-dashboard-app
    ports:
      - "8000:8000"
      - "8501:8501"
    volumes:
      - ../data:/app/data
    environment:
      - PYTHONUNBUFFERED=1
</file>

<file path="docker/Dockerfile">
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

COPY src /app/src
COPY data /app/data

EXPOSE 8000
EXPOSE 8501

CMD ["sh", "-c", "uvicorn src.api:app --host 0.0.0.0 --port 8000 & streamlit run src/streamlit_app.py --server.port 8501 --server.address 0.0.0.0"]
</file>

<file path="src/prompts/dashboard_system.md">
You generate an investor-facing diligence dashboard for a private AI startup.

Use ONLY data in the provided payload. If something is unknown or not disclosed, literally say "Not disclosed."

If a claim is marketing, attribute it: "The company states ..."

Never include personal emails or phone numbers.

Always include the final section "## Disclosure Gaps".

Required section order:

## Company Overview
## Business Model and GTM
## Funding & Investor Profile
## Growth Momentum
## Visibility & Market Sentiment
## Risks and Challenges
## Outlook
## Disclosure Gaps
</file>

<file path="src/api.py">
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
import json
from .structured_pipeline import load_payload
from .rag_pipeline import retrieve_context

app = FastAPI(title="PE Dashboard API", version="0.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

DATA_DIR = Path(__file__).resolve().parents[1] / "data"

@app.get("/health")
def health():
    return {"status": "ok"}

@app.get("/companies")
def list_companies():
    seed_path = DATA_DIR / "forbes_ai50_seed.json"
    if seed_path.exists():
        return json.loads(seed_path.read_text())
    return []

@app.post("/dashboard/structured")
def dashboard_structured(company_id: str = "00000000-0000-0000-0000-000000000000"):
    payload = load_payload(company_id)
    if not payload:
        raise HTTPException(status_code=404, detail="Payload not found")

    return {
        "markdown": (
            "## Company Overview\n"
            f"{payload.company_record.legal_name} ({payload.company_record.brand_name})\n\n"
            "## Business Model and GTM\nNot disclosed.\n\n"
            "## Funding & Investor Profile\nNot disclosed.\n\n"
            "## Growth Momentum\nNot disclosed.\n\n"
            "## Visibility & Market Sentiment\nNot disclosed.\n\n"
            "## Risks and Challenges\nNot disclosed.\n\n"
            "## Outlook\nNot disclosed.\n\n"
            "## Disclosure Gaps\n- Valuation not disclosed.\n"
        )
    }

@app.post("/dashboard/rag")
def dashboard_rag(company_name: str = "ExampleAI"):
    ctx = retrieve_context(company_name)
    return {
        "markdown": (
            f"## Company Overview\n{company_name} — generated from retrieved context.\n\n"
            "## Business Model and GTM\nNot disclosed.\n\n"
            "## Funding & Investor Profile\nNot disclosed.\n\n"
            "## Growth Momentum\nNot disclosed.\n\n"
            "## Visibility & Market Sentiment\nNot disclosed.\n\n"
            "## Risks and Challenges\nNot disclosed.\n\n"
            "## Outlook\nNot disclosed.\n\n"
            "## Disclosure Gaps\n- Not disclosed.\n"
        ),
        "retrieved": ctx
    }
</file>

<file path="src/evaluator.py">
def score_dashboard(factual: int, schema: int, provenance: int, hallucination: int, readability: int) -> int:
    return factual + schema + provenance + hallucination + readability
</file>

<file path="src/models.py">
from pydantic import BaseModel, HttpUrl
from typing import List, Optional
from datetime import date

class Provenance(BaseModel):
    source_url: HttpUrl
    crawled_at: str
    snippet: Optional[str] = None

class Company(BaseModel):
    company_id: str
    legal_name: str
    brand_name: Optional[str] = None
    website: Optional[HttpUrl] = None
    hq_city: Optional[str] = None
    hq_state: Optional[str] = None
    hq_country: Optional[str] = None
    founded_year: Optional[int] = None
    categories: List[str] = []
    related_companies: List[str] = []
    total_raised_usd: Optional[float] = None
    last_disclosed_valuation_usd: Optional[float] = None
    last_round_name: Optional[str] = None
    last_round_date: Optional[date] = None
    schema_version: str = "2.0.0"
    as_of: Optional[date] = None
    provenance: List[Provenance] = []

class Event(BaseModel):
    event_id: str
    company_id: str
    occurred_on: date
    event_type: str
    title: str
    description: Optional[str] = None
    round_name: Optional[str] = None
    investors: List[str] = []
    amount_usd: Optional[float] = None
    valuation_usd: Optional[float] = None
    actors: List[str] = []
    tags: List[str] = []
    schema_version: str = "2.0.0"
    provenance: List[Provenance] = []

class Snapshot(BaseModel):
    company_id: str
    as_of: date
    headcount_total: Optional[int] = None
    headcount_growth_pct: Optional[float] = None
    job_openings_count: Optional[int] = None
    engineering_openings: Optional[int] = None
    sales_openings: Optional[int] = None
    hiring_focus: List[str] = []
    pricing_tiers: List[str] = []
    active_products: List[str] = []
    geo_presence: List[str] = []
    confidence: Optional[float] = None
    schema_version: str = "2.0.0"
    provenance: List[Provenance] = []

class Product(BaseModel):
    product_id: str
    company_id: str
    name: str
    description: Optional[str] = None
    pricing_model: Optional[str] = None
    pricing_tiers_public: List[str] = []
    ga_date: Optional[date] = None
    integration_partners: List[str] = []
    github_repo: Optional[str] = None
    license_type: Optional[str] = None
    reference_customers: List[str] = []
    schema_version: str = "2.0.0"
    provenance: List[Provenance] = []

class Leadership(BaseModel):
    person_id: str
    company_id: str
    name: str
    role: str
    is_founder: bool = False
    start_date: Optional[date] = None
    end_date: Optional[date] = None
    previous_affiliation: Optional[str] = None
    education: Optional[str] = None
    linkedin: Optional[HttpUrl] = None
    schema_version: str = "2.0.0"
    provenance: List[Provenance] = []

class Visibility(BaseModel):
    company_id: str
    as_of: date
    news_mentions_30d: Optional[int] = None
    avg_sentiment: Optional[float] = None
    github_stars: Optional[int] = None
    glassdoor_rating: Optional[float] = None
    schema_version: str = "2.0.0"
    provenance: List[Provenance] = []

class Payload(BaseModel):
    company_record: Company
    events: List[Event] = []
    snapshots: List[Snapshot] = []
    products: List[Product] = []
    leadership: List[Leadership] = []
    visibility: List[Visibility] = []
    notes: Optional[str] = ""
    provenance_policy: Optional[str] = "Use only the sources you scraped. If a field is missing, write 'Not disclosed.' Do not infer valuation."
</file>

<file path="src/rag_pipeline.py">
from typing import List, Dict

def retrieve_context(company_name: str) -> List[Dict]:
    # TODO: replace with real retrieval from vector DB
    return [
        {
            "source_url": "https://example.ai/about",
            "text": f"{company_name} is an AI company providing automation tooling."
        }
    ]
</file>

<file path="src/streamlit_app.py">
import streamlit as st
import requests

API_BASE = "http://localhost:8000"

st.set_page_config(page_title="PE Dashboard (AI 50)", layout="wide")
st.title("Project ORBIT – PE Dashboard for Forbes AI 50")

try:
    companies = requests.get(f"{API_BASE}/companies", timeout=5).json()
except Exception:
    companies = []

names = [c["company_name"] for c in companies] if companies else ["ExampleAI"]
choice = st.selectbox("Select company", names)

col1, col2 = st.columns(2)

with col1:
    st.subheader("Structured pipeline")
    if st.button("Generate (Structured)"):
        resp = requests.post(f"{API_BASE}/dashboard/structured", params={"company_id": "00000000-0000-0000-0000-000000000000"})
        st.markdown(resp.json()["markdown"])

with col2:
    st.subheader("RAG pipeline")
    if st.button("Generate (RAG)"):
        resp = requests.post(f"{API_BASE}/dashboard/rag", params={"company_name": choice})
        st.markdown(resp.json()["markdown"])
        with st.expander("Retrieved context"):
            st.json(resp.json()["retrieved"])
</file>

<file path="src/structured_pipeline.py">
from pathlib import Path
from typing import Optional
from .models import Payload

DATA_DIR = Path(__file__).resolve().parents[1] / "data" / "payloads"

def load_payload(company_id: str) -> Optional[Payload]:
    fp = DATA_DIR / f"{company_id}.json"
    if not fp.exists():
        # fallback to starter
        starter = Path(__file__).resolve().parents[1] / "data" / "starter_payload.json"
        return Payload.model_validate_json(starter.read_text())
    return Payload.model_validate_json(fp.read_text())
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock
#poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
#pdm.lock
#pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
#pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/
</file>

<file path="CONTRIBUTION_ATTESTATION.txt">
WE ATTEST THAT WE HAVEN’T USED ANY OTHER STUDENTS’ WORK IN OUR ASSIGNMENT AND ABIDE BY THE
POLICIES LISTED IN THE STUDENT HANDBOOK

member1: __%
member2: __%
member3: __%
</file>

<file path="EVAL.md">
# RAG vs Structured Evaluation

| company | method       | factual (0–3) | schema (0–2) | provenance (0–2) | hallucination (0–2) | readability (0–1) | total |
|---------|--------------|---------------|--------------|------------------|----------------------|-------------------|-------|
|         | RAG          |               |              |                  |                      |                   |       |
|         | Structured   |               |              |                  |                      |                   |       |
</file>

<file path="requirements.txt">
fastapi==0.115.0
uvicorn==0.30.6
streamlit==1.38.0
pydantic==2.9.2
requests==2.32.3
python-multipart==0.0.9
</file>

<file path="Assignment.md">
# Assignment 2 — DAMG7245
## Case Study 2 — Project ORBIT (Part 1)
**Automating Private-Equity (PE) Intelligence for the Forbes AI 50**

### Setting
Quanta Capital Partners, a growth-stage investment firm, tracks the **Forbes AI 50** startups. Analysts currently open each company website, LinkedIn page, and press/blog page to collect basic investment signals: HQ, founding year, funding rounds, hiring momentum, leadership changes, and product focus. They then hand-write an investor-style diligence note.

This process:
- does not scale to all 50 companies,
- is hard to refresh daily, and
- is inconsistent across analysts.

To fix this, **Priya Rao, VP of Data Engineering**, launches **Project ORBIT**. Her goal: **build an automated, reproducible, cloud-hosted system** that can:

1. Ingest public data for **all Forbes AI 50** companies,
2. Build **two parallel generation pipelines**:
   - Unstructured → RAG → LLM → PE Dashboard
   - Structured (Pydantic + Instructor) → LLM → PE Dashboard
3. Compare the two dashboards for quality,
4. Run an **initial/full** pipeline and a **daily/update** pipeline in **Airflow**, and
5. Serve dashboards through **FastAPI + Streamlit** (dockerized) on **GCP or AWS**.

By the end of this assignment, the “Quanta team” (you) must deliver a **PE Dashboard Factory**.

---

## Learning Outcomes
- Build ingestion/orchestration with **Apache Airflow** (initial + daily)
- Build **RAG** with a vector database
- Build **structured-output** extraction with **Pydantic + instructor-style prompting**
- Design **LLM prompts** that emit investor dashboards in a fixed schema
- **Compare** 2 LLM pipelines with a rubric
- **Dockerize** FastAPI + Streamlit

---

## Phase 1 – Data Ingestion & Pipeline Bootstrap (Labs 0–3)

### Lab 0 — Project bootstrap & AI 50 seed
**Goal:** create a reproducible repo and seed list.

**Tasks**
1. Create a Git repo with folders:
   - `src/`, `dags/`, `data/`, `app/` (optional), `docker/`
2. Add `data/forbes_ai50_seed.json` (provided) — this has the **schema only**.  
   You must *populate it yourself* with the current Forbes AI 50 from https://www.forbes.com/lists/ai50/ .
3. Add a `README.md` with run instructions.

**Checkpoint**
- `git status` is clean
- `data/forbes_ai50_seed.json` exists

---

### Lab 1 — Scrape & store
**Goal:** pull source pages and store them to cloud (GCS or S3) or locally for dev.I recommend you create a folder for each company with subfolders for the initial pull and subsequent daily runs

**Tasks**
1. Write a Python scraper to fetch:
   - homepage
   - /about
   - /product or /platform
   - /careers
   - /blog or /news
2. Save **raw HTML** and a **clean-text** version
3. Emit metadata:
   ```json
   {
     "company_name": "...",
     "source_url": "...",
     "crawled_at": "2025-10-31T10:00:00Z"
   }
   ```

**Checkpoint**
- Companies scraped into `data/raw/<company_id>/...`

---

### Lab 2 — Full-load Airflow DAG
**Goal:** run ingestion for **all** AI 50.

**Tasks**
1. Create `dags/ai50_full_ingest_dag.py` with tasks:
   - load_company_list
   - scrape_company_pages (mapped / TaskGroup)
   - store_raw_to_cloud
2. Schedule: `@once`
3. Output: `raw/<company_id>/...` + metadata

**Checkpoint**
- DAG runs and completes for the AI50 companies
---

### Lab 3 — Daily/update Airflow DAG
**Goal:** refresh deltas daily.

**Tasks**
1. Create `dags/ai50_daily_refresh_dag.py`
2. Schedule: `0 3 * * *`
3. Re-scrape only changed or key pages (About, Careers, Blog)
4. Create subfolders for each run in the company folder
5. Log success/failure per company

**Checkpoint**
- DAG runs without breaking the full-load run

---

## Phase 2 – Knowledge Representation (Labs 4–6)

### Lab 4 — Vector DB & RAG index
**Goal:** support unstructured, retrieval-augmented dashboards.

**Tasks**
1. Chunk raw text (500–1,000 tokens)
2. Embed chunks and store in a local vector DB (FAISS, Chroma, Qdrant)
3. Add a FastAPI endpoint `/rag/search` to test retrieval

**Checkpoint**
- Querying “funding” or “leadership” for a company returns the right chunk

---

### Lab 5 — Structured extraction with Pydantic
**Goal:** normalize messy web text into clean objects to feed the LLM.

**Tasks**
1. Use `src/models.py` (provided) — Company, Event, Snapshot, Product, Leadership, Visibility
2. For each scraped source, call the LLM with an **instructor-style** prompt to fill the Pydantic model. 
3. NOTE: YOU WILL HAVE TO USE THE INSTRUTOR PYTHON LIBRARY. THIS IS JUST STARTER CODE
4. Save results as `data/structured/<company_id>.json`

**Checkpoint**
- At least 5 companies with full payloads (company + events + snapshots ...)
- We should be able to try it for any of the 50 companies
---

### Lab 6 — Payload assembly
**Goal:** build the exact payload that the dashboard prompt expects.

**Tasks**
1. Combine:
   - `company_record`
   - `events`
   - `snapshots`
   - `products`
   - `leadership`
   - `visibility`
   - `notes`
   - `provenance_policy`
2. Save to `data/payloads/<company_id>.json`

**Checkpoint**
- Payload validates and can be loaded by `src/structured_pipeline.py`

---

## Phase 3 – Dashboard Generation (Labs 7–9)

### Lab 7 — RAG Pipeline Dashboard
**Goal:** raw pages → vector DB → LLM → Markdown dashboard

**Tasks**
1. Implement `POST /dashboard/rag` in FastAPI
2. Retrieve top-k context for the company
3. Call LLM with the dashboard prompt (`src/prompts/dashboard_system.md`)
4. Enforce the 8-section output:

   1. ## Company Overview
   2. ## Business Model and GTM
   3. ## Funding & Investor Profile
   4. ## Growth Momentum
   5. ## Visibility & Market Sentiment
   6. ## Risks and Challenges
   7. ## Outlook
   8. ## Disclosure Gaps

**Checkpoint**
- “Not disclosed.” is used when data is missing

---

### Lab 8 — Structured Pipeline Dashboard
**Goal:** structured payload → LLM → Markdown dashboard

**Tasks**
1. Implement `POST /dashboard/structured`
2. Load `data/payloads/<company_id>.json`
3. Pass as context to LLM with the *same* prompt
4. Return Markdown

**Checkpoint**
- Output is more precise and less hallucinatory than RAG

---

### Lab 9 — Evaluation & Comparison
**Goal:** compare RAG vs Structured for at least **5 companies**.

**Tasks**
1. Use the rubric below
2. Fill out `EVAL.md`
3. Write 1-page reflection in the repo

**Rubric (10 points):**
- Factual correctness (0–3)
- Schema adherence (0–2)
- Provenance use (0–2)
- Hallucination control (0–2)
- Readability / investor usefulness (0–1)

---

## Phase 4 – Deployment & Automation (Labs 10–11)

### Lab 10 — Dockerize FastAPI + Streamlit
**Goal:** run app in container on **GCP or AWS**.

**Tasks**
1. Use provided Dockerfile (FastAPI + Streamlit only)
2. `docker build -t pe-dashboard .`
3. `docker-compose up` should:
   - start FastAPI at `http://localhost:8000`
   - start Streamlit at `http://localhost:8501`

**Checkpoint**
- Both apps run locally in Docker

---

### Lab 11 — DAG ↔ App integration
**Goal:** make data refresh visible in the app.

**Tasks**
1. At the end of the daily DAG, write latest payload to `data/payloads/`
2. App should read from that folder (or cloud bucket)
3. (Optional) Add notification if dashboard generation fails

**Checkpoint**
- After daily run, Streamlit shows updated company list

---

## Deliverables

1. **GitHub repo** named `pe-dashboard-ai50`
2. **Working FastAPI** (`/companies`, `/dashboard/rag`, `/dashboard/structured`)
3. **Working Streamlit** (dropdown → dashboard)
4. **Two Airflow DAGs** (`ai50_full_ingest_dag.py`, `ai50_daily_refresh_dag.py`)
5. **Docker** for FastAPI + Streamlit
6. **EVAL.md** with at least 5 companies
7. **Demo video ≤10 mins** (hosted, link in README)
8. **Contribution attestation** (provided template)

---

## Important Notes
- You must use **all 50** from Forbes AI 50
- If a field cannot be found → **“Not disclosed.”**
- **Never invent** ARR, MRR, valuation, customer logos, or pipeline.
- Always include **“## Disclosure Gaps”**.
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 srikanth krishnamurthy

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="README.md">
# Project ORBIT — PE Dashboard for Forbes AI 50

This is the starter package for **Assignment 2 — DAMG7245**.

## Run locally (dev)

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
uvicorn src.api:app --reload
# in another terminal
streamlit run src/streamlit_app.py
```

## Docker (app layer only)

```bash
cd docker
docker compose up --build
```

This starts:
- FastAPI: http://localhost:8000
- Streamlit: http://localhost:8501

# Add instructions on running on the cloud based on your setup and links to Codelabs, architecture diagrams etc.
</file>

</files>
